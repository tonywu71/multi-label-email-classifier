{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, classification_report, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub/body</th>\n",
       "      <th>urls/body</th>\n",
       "      <th>images/body</th>\n",
       "      <th>salutaions&amp;designation</th>\n",
       "      <th>ccs</th>\n",
       "      <th>bcced</th>\n",
       "      <th>images</th>\n",
       "      <th>urls</th>\n",
       "      <th>salutations</th>\n",
       "      <th>designation</th>\n",
       "      <th>...</th>\n",
       "      <th>org_api</th>\n",
       "      <th>org_youth4work</th>\n",
       "      <th>org_diu</th>\n",
       "      <th>org_zoovsupport</th>\n",
       "      <th>org_paypalexchanges</th>\n",
       "      <th>org_zen2makemytrip</th>\n",
       "      <th>org_agencenavigo</th>\n",
       "      <th>org_asus</th>\n",
       "      <th>org_nitkkr</th>\n",
       "      <th>org_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39666</th>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39667</th>\n",
       "      <td>0.079057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39668</th>\n",
       "      <td>0.049037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39669</th>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39670</th>\n",
       "      <td>0.110951</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39671 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sub/body  urls/body  images/body  salutaions&designation  ccs  bcced  \\\n",
       "0      0.001839   0.001096     0.000157                       0    0      0   \n",
       "1      0.002308   0.001606     0.000301                       0    0      0   \n",
       "2      5.250000   0.000000     0.000000                       0    0      0   \n",
       "3      0.000538   0.001771     0.001118                       0    0      0   \n",
       "4      0.000851   0.001745     0.000210                       0    0      0   \n",
       "...         ...        ...          ...                     ...  ...    ...   \n",
       "39666  0.000712   0.000690     0.000245                       0    0      0   \n",
       "39667  0.079057   0.000000     0.000000                       0    0      0   \n",
       "39668  0.049037   0.000000     0.000000                       0    0      0   \n",
       "39669  0.000258   0.001465     0.000291                       1    0      0   \n",
       "39670  0.110951   0.002882     0.000000                       0    0      0   \n",
       "\n",
       "       images  urls  salutations  designation  ...  org_api  org_youth4work  \\\n",
       "0           4    28            0            1  ...        0               0   \n",
       "1           6    32            0            0  ...        0               0   \n",
       "2           0     0            0            0  ...        0               0   \n",
       "3         108   171            0            0  ...        0               0   \n",
       "4          20   166            0            0  ...        0               0   \n",
       "...       ...   ...          ...          ...  ...      ...             ...   \n",
       "39666      11    31            0            0  ...        0               0   \n",
       "39667       0     0            0            0  ...        0               0   \n",
       "39668       0     0            1            0  ...        0               0   \n",
       "39669      27   136            1            1  ...        0               0   \n",
       "39670       0     2            0            0  ...        0               0   \n",
       "\n",
       "       org_diu  org_zoovsupport  org_paypalexchanges  org_zen2makemytrip  \\\n",
       "0            0                0                    0                   0   \n",
       "1            0                0                    0                   0   \n",
       "2            0                0                    0                   0   \n",
       "3            0                0                    0                   0   \n",
       "4            0                0                    0                   0   \n",
       "...        ...              ...                  ...                 ...   \n",
       "39666        0                0                    0                   0   \n",
       "39667        0                0                    0                   0   \n",
       "39668        0                0                    0                   0   \n",
       "39669        0                0                    0                   0   \n",
       "39670        0                0                    0                   0   \n",
       "\n",
       "       org_agencenavigo  org_asus  org_nitkkr  org_length  \n",
       "0                     0         0           0          16  \n",
       "1                     0         0           0           4  \n",
       "2                     0         0           0           4  \n",
       "3                     0         0           0          11  \n",
       "4                     0         0           0           7  \n",
       "...                 ...       ...         ...         ...  \n",
       "39666                 0         0           0           3  \n",
       "39667                 0         0           0           3  \n",
       "39668                 0         0           0           5  \n",
       "39669                 0         0           0           1  \n",
       "39670                 0         0           0           6  \n",
       "\n",
       "[39671 rows x 705 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"mustapha_train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'updates' in df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccs</th>\n",
       "      <th>bcced</th>\n",
       "      <th>images</th>\n",
       "      <th>urls</th>\n",
       "      <th>salutations</th>\n",
       "      <th>designation</th>\n",
       "      <th>chars_in_subject</th>\n",
       "      <th>chars_in_body</th>\n",
       "      <th>date_dayweek</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>org_api</th>\n",
       "      <th>org_youth4work</th>\n",
       "      <th>org_diu</th>\n",
       "      <th>org_zoovsupport</th>\n",
       "      <th>org_paypalexchanges</th>\n",
       "      <th>org_zen2makemytrip</th>\n",
       "      <th>org_agencenavigo</th>\n",
       "      <th>org_asus</th>\n",
       "      <th>org_nitkkr</th>\n",
       "      <th>org_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>36243</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27015</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>788</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>39504</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>178773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13674</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19845</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>17565</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9918</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17002 rows × 697 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ccs  bcced  images  urls  salutations  designation  chars_in_subject  \\\n",
       "0        0      0       7    56            0            0              67.0   \n",
       "1        0      0       5    33            0            0              27.0   \n",
       "2        0      0       0     2            1            0              22.0   \n",
       "3        0      0       8    53            0            0              79.0   \n",
       "4        0      0       0     0            0            0              24.0   \n",
       "...    ...    ...     ...   ...          ...          ...               ...   \n",
       "16997    1      0       0     8            0            0              73.0   \n",
       "16998    0      0       7    27            0            0              39.0   \n",
       "16999    0      0       0     0            0            0              25.0   \n",
       "17000    0      0       1     6            0            0              39.0   \n",
       "17001    0      0       2    22            0            0              29.0   \n",
       "\n",
       "       chars_in_body  date_dayweek  date_hour  ...  org_api  org_youth4work  \\\n",
       "0              36243             4          8  ...        0               0   \n",
       "1              27015             0         14  ...        0               0   \n",
       "2                788             1         10  ...        0               0   \n",
       "3              39504             4          9  ...        0               0   \n",
       "4             178773             1          1  ...        0               0   \n",
       "...              ...           ...        ...  ...      ...             ...   \n",
       "16997           2372             2         12  ...        0               0   \n",
       "16998          13674             5         12  ...        0               0   \n",
       "16999          19845             4         14  ...        0               0   \n",
       "17000          17565             3          9  ...        0               0   \n",
       "17001           9918             0         21  ...        0               0   \n",
       "\n",
       "       org_diu  org_zoovsupport  org_paypalexchanges  org_zen2makemytrip  \\\n",
       "0            0                0                    0                   0   \n",
       "1            0                0                    0                   0   \n",
       "2            0                0                    0                   0   \n",
       "3            0                0                    0                   0   \n",
       "4            0                0                    0                   0   \n",
       "...        ...              ...                  ...                 ...   \n",
       "16997        0                0                    0                   0   \n",
       "16998        0                0                    0                   0   \n",
       "16999        0                0                    0                   0   \n",
       "17000        0                0                    0                   0   \n",
       "17001        0                0                    0                   0   \n",
       "\n",
       "       org_agencenavigo  org_asus  org_nitkkr  org_length  \n",
       "0                     0         0           0           7  \n",
       "1                     0         0           0           6  \n",
       "2                     0         0           0           5  \n",
       "3                     0         0           0           7  \n",
       "4                     0         0           0           5  \n",
       "...                 ...       ...         ...         ...  \n",
       "16997                 0         0           0           6  \n",
       "16998                 0         0           0           5  \n",
       "16999                 0         0           0           5  \n",
       "17000                 0         0           0          12  \n",
       "17001                 0         0           0           8  \n",
       "\n",
       "[17002 rows x 697 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"mustapha_test.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'updates' in df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['updates', 'personal', 'promotions', \n",
    "          'forums', 'purchases', 'travel','spam', 'social']\n",
    "\n",
    "X_full = df.drop(columns=labels)\n",
    "y = df[labels]\n",
    "\n",
    "X_train, X_test, y_train_full, y_test_full = train_test_split(\n",
    "    X_full, y, test_size=0.25, random_state=1, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train_full, y_val_full = train_test_split(\n",
    "    X_train, y_train_full, test_size=0.20, random_state=1, stratify=y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- For updates: --------\n",
      "[17:25:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      6324\n",
      "           1       0.88      0.88      0.88      3594\n",
      "\n",
      "    accuracy                           0.91      9918\n",
      "   macro avg       0.91      0.91      0.91      9918\n",
      "weighted avg       0.91      0.91      0.91      9918\n",
      "\n",
      "Log loss: 3.0193043519348923\n",
      "-------- For personal: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:16] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      1888\n",
      "           1       0.98      0.99      0.98      8030\n",
      "\n",
      "    accuracy                           0.97      9918\n",
      "   macro avg       0.96      0.95      0.96      9918\n",
      "weighted avg       0.97      0.97      0.97      9918\n",
      "\n",
      "Log loss: 0.9193755296471184\n",
      "-------- For promotions: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      7936\n",
      "           1       0.89      0.80      0.85      1982\n",
      "\n",
      "    accuracy                           0.94      9918\n",
      "   macro avg       0.92      0.89      0.90      9918\n",
      "weighted avg       0.94      0.94      0.94      9918\n",
      "\n",
      "Log loss: 2.0372396159824495\n",
      "-------- For forums: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      8373\n",
      "           1       0.88      0.85      0.87      1545\n",
      "\n",
      "    accuracy                           0.96      9918\n",
      "   macro avg       0.93      0.91      0.92      9918\n",
      "weighted avg       0.96      0.96      0.96      9918\n",
      "\n",
      "Log loss: 1.4208471766352804\n",
      "-------- For purchases: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9835\n",
      "           1       0.94      0.61      0.74        83\n",
      "\n",
      "    accuracy                           1.00      9918\n",
      "   macro avg       0.97      0.81      0.87      9918\n",
      "weighted avg       1.00      1.00      1.00      9918\n",
      "\n",
      "Log loss: 0.1218854176864463\n",
      "-------- For travel: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:26:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9893\n",
      "           1       0.94      0.64      0.76        25\n",
      "\n",
      "    accuracy                           1.00      9918\n",
      "   macro avg       0.97      0.82      0.88      9918\n",
      "weighted avg       1.00      1.00      1.00      9918\n",
      "\n",
      "Log loss: 0.03482441657053306\n",
      "-------- For spam: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:26:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9880\n",
      "           1       0.92      0.63      0.75        38\n",
      "\n",
      "    accuracy                           1.00      9918\n",
      "   macro avg       0.96      0.82      0.87      9918\n",
      "weighted avg       1.00      1.00      1.00      9918\n",
      "\n",
      "Log loss: 0.05571909876118584\n",
      "-------- For social: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:26:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8917\n",
      "           1       0.97      0.95      0.96      1001\n",
      "\n",
      "    accuracy                           0.99      9918\n",
      "   macro avg       0.98      0.97      0.98      9918\n",
      "weighted avg       0.99      0.99      0.99      9918\n",
      "\n",
      "Log loss: 0.271632077790995\n"
     ]
    }
   ],
   "source": [
    "dic_models = dict()\n",
    "\n",
    "for label in tqdm(labels):\n",
    "    print(f\"-------- For {label}: --------\")\n",
    "    \n",
    "    y_train = y_train_full[label]\n",
    "    y_test = y_test_full[label]\n",
    "    \n",
    "    dic_models[label] = xgb.XGBClassifier(objective='binary:logistic')\n",
    "    dic_models[label].fit(X_train, y_train)\n",
    "    \n",
    "    y_preds = dic_models[label].predict(X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_preds))\n",
    "    print(f\"Log loss: {log_loss(y_test, y_preds)}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per day for personnal and updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch for one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['updates', 'personal', 'promotions', \n",
    "          'forums', 'purchases', 'travel','spam', 'social']\n",
    "current_labels = ['updates', 'personal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Monday and `updates`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekday = df[df[\"date_dayweek\"]==0]\n",
    "\n",
    "X_full = df_weekday.drop(columns=labels)\n",
    "y = df_weekday[current_labels]\n",
    "\n",
    "X_train, X_test, y_train_full, y_test_full = train_test_split(\n",
    "    X_full, y, test_size=0.25, random_state=1, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train_full, y_val_full = train_test_split(\n",
    "    X_train, y_train_full, test_size=0.20, random_state=1, stratify=y_train_full)\n",
    "\n",
    "\n",
    "y_train = y_train_full['updates']\n",
    "y_test = y_test_full['updates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   53.0s finished\n"
     ]
    }
   ],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'n_estimators': [100],\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [1],\n",
    "        'subsample': [0,4, 0.6, 0.8],\n",
    "        'colsample_bytree': [0.8],\n",
    "        'max_depth': range(2, 12)\n",
    "        }\n",
    "\n",
    "# It's more efficient to use parallelization for GridSearch so we set n_jobs=1:\n",
    "clf = xgb.XGBClassifier(n_jobs=1, verbosity=0, use_label_encoder=False) \n",
    "\n",
    "grid = RandomizedSearchCV(\n",
    "    clf,\n",
    "    params,\n",
    "    n_iter=50,\n",
    "    n_jobs=4,  # -1 means using all processors\n",
    "    scoring=\"neg_log_loss\",\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train, verbose=3)\n",
    "\n",
    "model = grid.best_estimator_\n",
    "\n",
    "# Save the optimal hyperparameters\n",
    "with open('XGBClassifier_params_0_updates.json', \"w\") as f:  \n",
    "    json.dump(grid.best_params_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8,\n",
       " 'n_estimators': 100,\n",
       " 'min_child_weight': 1,\n",
       " 'max_depth': 11,\n",
       " 'gamma': 1,\n",
       " 'colsample_bytree': 0.8}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3406412905170766"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=11,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=1, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['updates', 'personal', 'promotions', \n",
    "          'forums', 'purchases', 'travel','spam', 'social']\n",
    "current_labels = ['updates', 'personal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6728     1\n",
       "1298     1\n",
       "3289     3\n",
       "25202    4\n",
       "296      2\n",
       "        ..\n",
       "8895     1\n",
       "3236     1\n",
       "12222    0\n",
       "29832    1\n",
       "29065    5\n",
       "Name: date_dayweek, Length: 23802, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.date_dayweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- For 0 and updates: --------\n",
      "[17:33:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       534\n",
      "           1       0.88      0.84      0.86       309\n",
      "\n",
      "    accuracy                           0.90       843\n",
      "   macro avg       0.89      0.89      0.89       843\n",
      "weighted avg       0.90      0.90      0.90       843\n",
      "\n",
      "Log loss: 3.5235638850145152\n",
      "\n",
      "\n",
      "\n",
      "-------- For 0 and personal: --------\n",
      "[17:33:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90       134\n",
      "           1       0.98      0.99      0.98       709\n",
      "\n",
      "    accuracy                           0.97       843\n",
      "   macro avg       0.95      0.93      0.94       843\n",
      "weighted avg       0.97      0.97      0.97       843\n",
      "\n",
      "Log loss: 1.1062402797377255\n",
      "\n",
      "\n",
      "\n",
      "-------- For 1 and updates: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:33:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      1001\n",
      "           1       0.85      0.83      0.84       538\n",
      "\n",
      "    accuracy                           0.89      1539\n",
      "   macro avg       0.88      0.88      0.88      1539\n",
      "weighted avg       0.89      0.89      0.89      1539\n",
      "\n",
      "Log loss: 3.8152410363412814\n",
      "\n",
      "\n",
      "\n",
      "-------- For 1 and personal: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:33:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87       254\n",
      "           1       0.97      0.98      0.97      1285\n",
      "\n",
      "    accuracy                           0.96      1539\n",
      "   macro avg       0.93      0.91      0.92      1539\n",
      "weighted avg       0.96      0.96      0.96      1539\n",
      "\n",
      "Log loss: 1.4587735214856423\n",
      "\n",
      "\n",
      "\n",
      "-------- For 2 and updates: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:33:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      1059\n",
      "           1       0.90      0.83      0.86       665\n",
      "\n",
      "    accuracy                           0.90      1724\n",
      "   macro avg       0.90      0.89      0.89      1724\n",
      "weighted avg       0.90      0.90      0.90      1724\n",
      "\n",
      "Log loss: 3.4659259235297917\n",
      "\n",
      "\n",
      "\n",
      "-------- For 2 and personal: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:33:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       405\n",
      "           1       0.96      0.98      0.97      1319\n",
      "\n",
      "    accuracy                           0.95      1724\n",
      "   macro avg       0.94      0.93      0.93      1724\n",
      "weighted avg       0.95      0.95      0.95      1724\n",
      "\n",
      "Log loss: 1.5827170038671028\n",
      "\n",
      "\n",
      "\n",
      "-------- For 3 and updates: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:33:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      1011\n",
      "           1       0.81      0.78      0.80       494\n",
      "\n",
      "    accuracy                           0.87      1505\n",
      "   macro avg       0.85      0.85      0.85      1505\n",
      "weighted avg       0.87      0.87      0.87      1505\n",
      "\n",
      "Log loss: 4.566969611929152\n",
      "\n",
      "\n",
      "\n",
      "-------- For 3 and personal: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       254\n",
      "           1       0.97      0.98      0.98      1251\n",
      "\n",
      "    accuracy                           0.96      1505\n",
      "   macro avg       0.94      0.91      0.93      1505\n",
      "weighted avg       0.96      0.96      0.96      1505\n",
      "\n",
      "Log loss: 1.354033083851787\n",
      "\n",
      "\n",
      "\n",
      "-------- For 4 and updates: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      1072\n",
      "           1       0.84      0.82      0.83       586\n",
      "\n",
      "    accuracy                           0.88      1658\n",
      "   macro avg       0.87      0.87      0.87      1658\n",
      "weighted avg       0.88      0.88      0.88      1658\n",
      "\n",
      "Log loss: 4.124700656181052\n",
      "\n",
      "\n",
      "\n",
      "-------- For 4 and personal: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       341\n",
      "           1       0.97      0.97      0.97      1317\n",
      "\n",
      "    accuracy                           0.96      1658\n",
      "   macro avg       0.94      0.93      0.93      1658\n",
      "weighted avg       0.96      0.96      0.96      1658\n",
      "\n",
      "Log loss: 1.4790607413411203\n",
      "\n",
      "\n",
      "\n",
      "-------- For 5 and updates: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1035\n",
      "           1       0.82      0.82      0.82       533\n",
      "\n",
      "    accuracy                           0.88      1568\n",
      "   macro avg       0.86      0.86      0.86      1568\n",
      "weighted avg       0.88      0.88      0.88      1568\n",
      "\n",
      "Log loss: 4.273342462475021\n",
      "\n",
      "\n",
      "\n",
      "-------- For 5 and personal: --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       274\n",
      "           1       0.98      0.99      0.98      1294\n",
      "\n",
      "    accuracy                           0.97      1568\n",
      "   macro avg       0.95      0.93      0.94      1568\n",
      "weighted avg       0.97      0.97      0.97      1568\n",
      "\n",
      "Log loss: 1.1013803615199629\n",
      "\n",
      "\n",
      "\n",
      "-------- For 6 and updates: --------\n",
      "[17:34:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       613\n",
      "           1       0.90      0.88      0.89       470\n",
      "\n",
      "    accuracy                           0.91      1083\n",
      "   macro avg       0.90      0.90      0.90      1083\n",
      "weighted avg       0.91      0.91      0.91      1083\n",
      "\n",
      "Log loss: 3.2529942505633516\n",
      "\n",
      "\n",
      "\n",
      "-------- For 6 and personal: --------\n",
      "[17:34:16] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1607604592557/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ml/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       225\n",
      "           1       0.98      0.98      0.98       858\n",
      "\n",
      "    accuracy                           0.97      1083\n",
      "   macro avg       0.95      0.94      0.95      1083\n",
      "weighted avg       0.97      0.97      0.97      1083\n",
      "\n",
      "Log loss: 1.1481188751272573\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dic_models = dict()\n",
    "\n",
    "for weekday in range(7):\n",
    "    df_weekday = df[df[\"date_dayweek\"]==weekday]\n",
    "    \n",
    "    for label in current_labels:\n",
    "        key = (weekday, label)\n",
    "        \n",
    "        print(f\"-------- For {weekday} and {label}: --------\")\n",
    "        \n",
    "        X_full = df_weekday.drop(columns=labels)\n",
    "        y = df_weekday[current_labels]\n",
    "\n",
    "        X_train, X_test, y_train_full, y_test_full = train_test_split(\n",
    "            X_full, y, test_size=0.25, random_state=1, stratify=y)\n",
    "\n",
    "        X_train, X_val, y_train_full, y_val_full = train_test_split(\n",
    "            X_train, y_train_full, test_size=0.20, random_state=1, stratify=y_train_full)\n",
    "\n",
    "        \n",
    "        y_train = y_train_full[label]\n",
    "        y_test = y_test_full[label]\n",
    "\n",
    "        dic_models[key] = xgb.XGBClassifier(objective='binary:logistic')\n",
    "        dic_models[key].fit(X_train, y_train)\n",
    "\n",
    "        y_preds = dic_models[key].predict(X_test)\n",
    "\n",
    "        print(classification_report(y_test, y_preds))\n",
    "        print(f\"Log loss: {log_loss(y_test, y_preds)}\")\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
